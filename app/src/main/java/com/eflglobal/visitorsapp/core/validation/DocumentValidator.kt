package com.eflglobal.visitorsapp.core.validation

import android.graphics.Bitmap
import com.eflglobal.visitorsapp.core.ocr.DocumentDataExtractor
import com.eflglobal.visitorsapp.core.ocr.DocumentProcessingPipeline
import com.eflglobal.visitorsapp.data.local.dao.OcrMetricDao
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.latin.TextRecognizerOptions
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlin.coroutines.resume
import kotlin.coroutines.suspendCoroutine
import kotlin.math.abs
import kotlin.math.sqrt

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * DocumentValidator â€” Central validation engine for identity documents.
 *
 * Validation pipeline (applied sequentially, fails fast):
 *
 *   STEP 1 â€” Sharpness Gate (Laplacian variance on full-res bitmap)
 *            Rejects blurry images before any expensive processing.
 *
 *   STEP 2 â€” Document Crop
 *            Crops the central region matching the orange guide frame (70% width,
 *            1.6:1 aspect ratio), discarding background noise.
 *
 *   STEP 3 â€” Post-crop Sharpness Re-check
 *            Second Laplacian pass on the cropped region (stricter threshold).
 *
 *   STEP 4 â€” OCR Extraction (ML Kit)
 *            Extracts all text, name, document number, date of birth.
 *
 *   STEP 5 â€” Document Type Validation
 *            Checks for identity-document-exclusive keywords and numeric patterns.
 *            Front and back side each have tailored keyword sets.
 *
 *   STEP 6 â€” Duplicate-side Detection (back side only)
 *            Double-check: OCR Jaccard similarity + perceptual hash (pHash).
 *            Both must agree (or fallback gracefully) before accepting.
 *
 * Every step produces a typed result so callers can show granular feedback.
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */
object DocumentValidator {

    // â”€â”€â”€ Thresholds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /** Minimum Laplacian-variance sharpness on the RAW captured bitmap. */
    const val RAW_SHARPNESS_MIN = 15f

    /** Minimum Laplacian-variance sharpness on the CROPPED document region. */
    const val CROP_SHARPNESS_MIN = 20f

    /** Minimum OCR character count to consider a side "readable". */
    const val OCR_MIN_CHARS = 12

    /** Jaccard similarity threshold for OCR duplicate detection. */
    const val JACCARD_DUPLICATE_THRESHOLD = 0.50f

    /** pHash Hamming distance threshold (lower = stricter). */
    const val PHASH_DUPLICATE_THRESHOLD = 10

    // â”€â”€â”€ Result types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /** Overall result of the full validation pipeline. */
    sealed class ValidationResult {
        /** Document passed all checks. */
        data class Accepted(
            val croppedBitmap: Bitmap,
            val ocrData: OcrData
        ) : ValidationResult()

        /** A specific step failed â€” carries a user-facing message. */
        data class Rejected(
            val step: ValidationStep,
            val reason: String,       // internal key for logging
            val userMessage: String   // localised, shown in UI
        ) : ValidationResult()
    }

    enum class ValidationStep {
        RAW_SHARPNESS,
        CROP,
        CROP_SHARPNESS,
        OCR,
        DOCUMENT_TYPE,
        DUPLICATE_SIDE
    }

    /** Structured OCR extraction result. */
    data class OcrData(
        val fullText: String,
        val detectedName: String?,
        val firstName: String?,
        val lastName: String?,
        val detectedDocNumber: String?,
        val detectedDob: String?,
        val lineCount: Int,
        val wordCount: Int,
        val charCount: Int,
        val extractionSource: DocumentDataExtractor.ExtractionSource =
            DocumentDataExtractor.ExtractionSource.NONE,
        val extractionConfidence: DocumentDataExtractor.Confidence =
            DocumentDataExtractor.Confidence.NONE,
        /** Full pipeline result â€” available for per-field confidence access and metrics. */
        val pipelineResult: DocumentProcessingPipeline.PipelineResult? = null
    )

    // â”€â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * All user-facing error messages used by the validation pipeline.
     * Build this in the UI layer with `stringResource` so the system locale is
     * respected automatically â€” no hardcoded strings inside the validator.
     */
    data class ValidationMessages(
        val rawBlurry:      String,
        val cropFailed:     String,
        val cropBlurry:     String,
        val noText:         String,
        val notDocument:    String,
        val notRecognised:  String,
        val duplicateSide:  String
    )

    /**
     * Runs the full validation pipeline on [rawBitmap].
     *
     * @param rawBitmap       Full-resolution bitmap from the camera.
     * @param isBackSide      True when scanning the back/reverse side.
     * @param referenceBitmap Previously accepted front-side bitmap (for dup check).
     * @param messages        Localised error strings â€” build from stringResource in the UI.
     */
    suspend fun validate(
        rawBitmap: Bitmap,
        isBackSide: Boolean = false,
        referenceBitmap: Bitmap? = null,
        messages: ValidationMessages
    ): ValidationResult {

        // â”€â”€ STEP 1: Raw sharpness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val rawSharpness = calculateLaplacianVariance(rawBitmap)
        log("STEP 1 â€” raw sharpness: $rawSharpness (min=$RAW_SHARPNESS_MIN)")

        if (rawSharpness < RAW_SHARPNESS_MIN) {
            return ValidationResult.Rejected(
                step        = ValidationStep.RAW_SHARPNESS,
                reason      = "raw_blurry(${"%.1f".format(rawSharpness)})",
                userMessage = messages.rawBlurry
            )
        }

        // â”€â”€ STEP 2: Crop document region â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val cropped = try {
            cropDocumentRegion(rawBitmap)
        } catch (e: Exception) {
            log("STEP 2 â€” crop failed: ${e.message}")
            return ValidationResult.Rejected(
                step        = ValidationStep.CROP,
                reason      = "crop_failed",
                userMessage = messages.cropFailed
            )
        }
        log("STEP 2 â€” crop OK: ${cropped.width}Ã—${cropped.height}")

        // â”€â”€ STEP 3: Cropped sharpness re-check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val cropSharpness = calculateLaplacianVariance(cropped)
        log("STEP 3 â€” crop sharpness: $cropSharpness (min=$CROP_SHARPNESS_MIN)")

        if (cropSharpness < CROP_SHARPNESS_MIN) {
            return ValidationResult.Rejected(
                step        = ValidationStep.CROP_SHARPNESS,
                reason      = "crop_blurry(${"%.1f".format(cropSharpness)})",
                userMessage = messages.cropBlurry
            )
        }

        // â”€â”€ STEP 4: OCR extraction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val ocrData = try {
            runOcr(cropped)
        } catch (e: Exception) {
            log("STEP 4 â€” OCR failed: ${e.message}")
            // OCR failure is non-blocking â€” proceed with empty data
            OcrData(
                fullText             = "",
                detectedName         = null,
                firstName            = null,
                lastName             = null,
                detectedDocNumber    = null,
                detectedDob          = null,
                lineCount            = 0,
                wordCount            = 0,
                charCount            = 0,
                extractionSource     = DocumentDataExtractor.ExtractionSource.NONE,
                extractionConfidence = DocumentDataExtractor.Confidence.NONE
            )
        }
        log("STEP 4 â€” OCR: chars=${ocrData.charCount} lines=${ocrData.lineCount} name=${ocrData.detectedName} docNum=${ocrData.detectedDocNumber}")

        // â”€â”€ STEP 5: Document-type validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val docCheck = checkDocumentType(ocrData, isBackSide)
        log("STEP 5 â€” docType: isDoc=${docCheck.isDocument} score=${docCheck.score} reason=${docCheck.reason}")

        if (!docCheck.isDocument) {
            val msg = when (docCheck.reason) {
                "no_text"      -> messages.noText
                "not_document" -> messages.notDocument
                else           -> messages.notRecognised
            }
            return ValidationResult.Rejected(
                step        = ValidationStep.DOCUMENT_TYPE,
                reason      = "doc_type:${docCheck.reason}",
                userMessage = msg
            )
        }

        // â”€â”€ STEP 6: Duplicate-side check (back side only) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if (isBackSide && referenceBitmap != null) {
            val dupResult = checkDuplicateSide(
                frontBitmap = referenceBitmap,
                backBitmap  = cropped,
                ocrData     = ocrData
            )
            log("STEP 6 â€” dup: isDup=${dupResult.isDuplicate} jaccardSim=${dupResult.jaccardSimilarity} pHashDist=${dupResult.pHashDistance} reason=${dupResult.reason}")

            if (dupResult.isDuplicate) {
                return ValidationResult.Rejected(
                    step        = ValidationStep.DUPLICATE_SIDE,
                    reason      = "duplicate:${dupResult.reason}",
                    userMessage = messages.duplicateSide
                )
            }
        }

        // â”€â”€ ALL STEPS PASSED â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        log("âœ… Document accepted â€” sharpness(raw=$rawSharpness crop=$cropSharpness) ocrChars=${ocrData.charCount}")
        return ValidationResult.Accepted(
            croppedBitmap = cropped,
            ocrData       = ocrData
        )
    }

    // â”€â”€â”€ STEP 2: Document Crop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Crops the central document region from [bitmap].
     *
     * CameraX with ROTATION_90 delivers landscape bitmaps (width > height).
     * If portrait is received, it is rotated to landscape first.
     *
     * The crop matches the on-screen guide frame: 70% of screen width at 1.6:1 AR.
     * Mapped to image coordinates: 55% of image width, centred.
     */
    fun cropDocumentRegion(bitmap: Bitmap): Bitmap {
        // Normalise to landscape
        val src = if (bitmap.height > bitmap.width) {
            val m = android.graphics.Matrix().apply { postRotate(90f) }
            Bitmap.createBitmap(bitmap, 0, 0, bitmap.width, bitmap.height, m, true)
        } else {
            bitmap
        }

        val imgW = src.width.toFloat()
        val imgH = src.height.toFloat()

        // 65% of image width â€” generous crop so field labels near edges are not cut.
        // (was 55%, increased to capture more of the document area)
        val cropW      = (imgW * 0.65f).toInt()
        val cropH      = minOf((cropW / 1.6f).toInt(), (imgH * 0.88f).toInt())
        val finalCropW = (cropH * 1.6f).toInt().coerceAtMost(cropW)

        val left  = ((imgW - finalCropW) / 2f).toInt().coerceAtLeast(0)
        val top   = ((imgH - cropH)      / 2f).toInt().coerceAtLeast(0)
        val safeW = finalCropW.coerceAtMost(src.width  - left)
        val safeH = cropH.coerceAtMost(src.height - top)

        val cropped = Bitmap.createBitmap(src, left, top, safeW, safeH)
        if (src !== bitmap) src.recycle()

        log("âœ‚ï¸ Crop: ${bitmap.width}Ã—${bitmap.height} â†’ ${cropped.width}Ã—${cropped.height}")
        return cropped
    }

    // â”€â”€â”€ STEP 1 & 3: Sharpness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Computes the Laplacian variance of [bitmap] as a sharpness score.
     * Higher = sharper.  Sampled every other pixel for performance.
     */
    fun calculateLaplacianVariance(bitmap: Bitmap): Float {
        val w      = bitmap.width
        val h      = bitmap.height
        val pixels = IntArray(w * h)
        bitmap.getPixels(pixels, 0, w, 0, 0, w, h)

        var sum   = 0.0
        var sumSq = 0.0
        var count = 0

        val step = 2 // sample every 2nd pixel â€” fast, accurate enough
        for (y in step until h - step step step) {
            for (x in step until w - step step step) {
                val idx = y * w + x
                fun gray(px: Int) = ((px shr 16 and 0xFF) * 0.299
                        + (px shr 8  and 0xFF) * 0.587
                        + (px        and 0xFF) * 0.114)

                val c  = gray(pixels[idx])
                val t  = gray(pixels[(y - step) * w + x])
                val b  = gray(pixels[(y + step) * w + x])
                val l  = gray(pixels[y * w + (x - step)])
                val r  = gray(pixels[y * w + (x + step)])
                val lap = abs(4 * c - t - b - l - r)

                sum   += lap
                sumSq += lap * lap
                count++
            }
        }

        if (count == 0) return 0f
        val mean = sum / count
        return sqrt((sumSq / count) - (mean * mean)).toFloat()
    }

    // â”€â”€â”€ STEP 4: OCR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Runs ML Kit OCR â†’ DocumentProcessingPipeline (Classifier â†’ MRZ â†’ Scoring â†’ Metrics)
     * and returns structured [OcrData].
     *
     * @param ocrMetricDao  Optional â€” when provided, each scan is logged for analytics.
     */
    suspend fun runOcr(bitmap: Bitmap, ocrMetricDao: OcrMetricDao? = null): OcrData =
        suspendCoroutine { cont ->
        val recognizer = TextRecognition.getClient(TextRecognizerOptions.DEFAULT_OPTIONS)

        // Scale up if image is small â€” ML Kit works best at 1080p+
        val processedBitmap = if (bitmap.width < 800 || bitmap.height < 500) {
            val scale = maxOf(800f / bitmap.width, 500f / bitmap.height)
            Bitmap.createScaledBitmap(
                bitmap,
                (bitmap.width  * scale).toInt().coerceAtLeast(1),
                (bitmap.height * scale).toInt().coerceAtLeast(1),
                true
            )
        } else bitmap

        recognizer.process(InputImage.fromBitmap(processedBitmap, 0))
            .addOnSuccessListener { visionText ->
                val fullText = visionText.text
                val lineCount = visionText.textBlocks.sumOf { it.lines.size }
                val wordCount = fullText.trim().split(Regex("\\s+")).count { it.length >= 2 }
                val charCount = fullText.trim().length

                log("STEP 4 OCR â€” ${processedBitmap.width}Ã—${processedBitmap.height} â†’ chars=$charCount lines=$lineCount")
                log("STEP 4 OCR full text: ${fullText.take(400)}")

                if (processedBitmap !== bitmap) processedBitmap.recycle()

                // Pipeline is suspend â€” launch an IO coroutine and resume the continuation when done
                CoroutineScope(Dispatchers.IO).launch {
                    val result = DocumentProcessingPipeline.process(
                        fullText     = fullText,
                        visionText   = visionText,
                        ocrMetricDao = ocrMetricDao
                    )

                    val detectedName = listOfNotNull(
                        result.autoFirstName,
                        result.autoLastName
                    ).joinToString(" ").ifBlank { null }

                    cont.resume(OcrData(
                        fullText             = fullText,
                        detectedName         = detectedName,
                        firstName            = result.firstName.value,
                        lastName             = result.lastName.value,
                        detectedDocNumber    = result.documentNumber.value,
                        detectedDob          = null,
                        lineCount            = lineCount,
                        wordCount            = wordCount,
                        charCount            = charCount,
                        extractionSource     = mapFieldSource(result.firstName.source),
                        extractionConfidence = mapConfidence(result.firstName.confidence),
                        pipelineResult       = result
                    ))
                }
            }
            .addOnFailureListener { e ->
                log("STEP 4 OCR FAILED: ${e.message}")
                if (processedBitmap !== bitmap) processedBitmap.recycle()
                cont.resume(OcrData(
                    fullText             = "",
                    detectedName         = null,
                    firstName            = null,
                    lastName             = null,
                    detectedDocNumber    = null,
                    detectedDob          = null,
                    lineCount            = 0,
                    wordCount            = 0,
                    charCount            = 0,
                    extractionSource     = DocumentDataExtractor.ExtractionSource.NONE,
                    extractionConfidence = DocumentDataExtractor.Confidence.NONE,
                    pipelineResult       = null
                ))
            }
    }

    /** Map new FieldSource â†’ legacy ExtractionSource for backward-compat display. */
    private fun mapFieldSource(
        source: com.eflglobal.visitorsapp.domain.model.FieldSource
    ): DocumentDataExtractor.ExtractionSource = when (source) {
        com.eflglobal.visitorsapp.domain.model.FieldSource.MRZ        -> DocumentDataExtractor.ExtractionSource.MRZ
        com.eflglobal.visitorsapp.domain.model.FieldSource.LABEL_OCR  -> DocumentDataExtractor.ExtractionSource.OCR_KEYED
        com.eflglobal.visitorsapp.domain.model.FieldSource.ENTITY,
        com.eflglobal.visitorsapp.domain.model.FieldSource.HEURISTIC  -> DocumentDataExtractor.ExtractionSource.OCR_HEURISTIC
        com.eflglobal.visitorsapp.domain.model.FieldSource.NONE       -> DocumentDataExtractor.ExtractionSource.NONE
    }

    /** Map numeric confidence â†’ legacy Confidence enum. */
    private fun mapConfidence(conf: Float): DocumentDataExtractor.Confidence = when {
        conf >= 0.80f -> DocumentDataExtractor.Confidence.HIGH
        conf >= 0.60f -> DocumentDataExtractor.Confidence.MEDIUM
        conf >= 0.30f -> DocumentDataExtractor.Confidence.LOW
        else          -> DocumentDataExtractor.Confidence.NONE
    }

    // â”€â”€â”€ STEP 5: Document-type validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    data class DocTypeResult(
        val isDocument: Boolean,
        val score: Int,
        val reason: String
    )

    /**
     * Exclusive front-side keywords â€” words that appear on ID documents but
     * almost never on laptops, posters, or random objects.
     */
    private val FRONT_KEYWORDS = setOf(
        // Spanish
        "nombres", "apellidos", "apellido", "nacimiento", "vencimiento",
        "emisiÃ³n", "emision", "identidad", "identificacion", "identificaciÃ³n",
        "dui", "nacionalidad", "ministerio", "repÃºblica", "republica",
        "salvadoreÃ±o", "salvadorena", "cedula", "licencia de conducir",
        // English / international
        "surname", "forename", "given name", "given names", "first name",
        "nationality", "expiry", "expiration", "date of birth",
        "passport no", "passport number", "identity card", "id card",
        "driver licence", "driver license", "drivers license",
        "place of birth", "sex", "issuing authority",
        // MRZ
        "<<<"
    )

    /**
     * Exclusive back-side keywords.
     */
    private val BACK_KEYWORDS = setOf(
        // Address / residence
        "domicilio", "direcciÃ³n", "direccion", "address", "residencia",
        // Administrative divisions
        "municipio", "departamento", "canton", "cantÃ³n", "barrio", "colonia",
        "ciudad", "distrito", "provincia",
        // Back-side specific fields
        "profesiÃ³n", "profesion", "ocupacion", "ocupaciÃ³n", "profession",
        "estatura", "height", "talla",
        "firma", "signature", "huella",
        "estado civil", "civil status", "marital status",
        "lugar de nacimiento", "birthplace",
        "emisiÃ³n", "emision", "issued", "expedido",
        "vencimiento", "expiry", "expiration",
        "cÃ³digo", "codigo", "code", "barcode",
        "ministerio", "registro", "civil", "republic", "republica",
        "<<<"
    )

    /** Numeric / alphanumeric patterns that strongly suggest an ID document. */
    private val DOC_PATTERNS = listOf(
        Regex("""\b\d{8}-\d\b"""),             // DUI: 12345678-9
        Regex("""\b\d{9}\b"""),                 // DUI no hyphen
        Regex("""\b[A-Z]{1,2}\d{6,8}\b"""),    // Passport: PA123456
        Regex("""\b\d{2}[/.-]\d{2}[/.-]\d{4}\b"""), // Dates
        Regex("""\b\d{4}[/.-]\d{2}[/.-]\d{2}\b"""), // ISO dates
        Regex("""[A-Z0-9<]{30,44}""")           // MRZ line
    )

    private fun checkDocumentType(ocrData: OcrData, isBackSide: Boolean): DocTypeResult {
        val text  = ocrData.fullText
        val lower = text.lowercase()

        // Minimum text requirement
        if (ocrData.charCount < 8 || ocrData.wordCount < 2) {
            return DocTypeResult(isDocument = false, score = 0, reason = "no_text")
        }

        val keywords = if (isBackSide) BACK_KEYWORDS else FRONT_KEYWORDS
        val keyHits  = keywords.count { lower.contains(it) }
        val patHits  = DOC_PATTERNS.count { it.containsMatchIn(text) }

        // Score: each keyword = 2pts, each pattern = 3pts
        val score = keyHits * 2 + patHits * 3

        log("  docType score=$score keyHits=$keyHits patHits=$patHits isBack=$isBackSide")

        return if (isBackSide) {
            // Back side: more permissive.
            // Accept if scoreâ‰¥2, OR has enough structured text (â‰¥4 lines, â‰¥5 words)
            val accepted = score >= 2 || (ocrData.lineCount >= 4 && ocrData.wordCount >= 5)
            DocTypeResult(
                isDocument = accepted,
                score      = score,
                reason     = if (accepted) "ok" else "not_document"
            )
        } else {
            // Front side: strict.
            // Require scoreâ‰¥4 (e.g. 2 keywords, or 1 keyword + 1 pattern)
            val accepted = score >= 4
            DocTypeResult(
                isDocument = accepted,
                score      = score,
                reason     = if (accepted) "ok" else "not_document"
            )
        }
    }

    // â”€â”€â”€ STEP 6: Duplicate-side detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    data class DupCheckResult(
        val isDuplicate: Boolean,
        val jaccardSimilarity: Float,
        val pHashDistance: Int,
        val reason: String   // "jaccard" | "phash" | "both" | "not_duplicate" | "insufficient_text"
    )

    /**
     * Double-checks that [backBitmap] is NOT the same side as [frontBitmap].
     *
     * Method A â€” OCR Jaccard similarity (text-based, very reliable when both
     *   sides have enough text; short-circuits to NOT-duplicate when either side
     *   has < MIN_TOKENS tokens).
     *
     * Method B â€” Perceptual hash (pixel-based, works even when OCR yields little
     *   text).
     *
     * Decision logic:
     *   â€¢ If Method A has sufficient text:
     *       - If Jaccard â‰¥ threshold â†’ DUPLICATE (confirmed by text content)
     *       - If Jaccard < threshold â†’ NOT duplicate (text differs)
     *   â€¢ If Method A has insufficient text:
     *       - Fall back to Method B exclusively.
     */
    private suspend fun checkDuplicateSide(
        frontBitmap: Bitmap,
        backBitmap: Bitmap,
        ocrData: OcrData   // already computed OCR for backBitmap â€” reuse it
    ): DupCheckResult {

        // â”€â”€ Method A: Jaccard OCR similarity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val frontText   = extractRawOcrText(frontBitmap)
        val frontTokens = tokenize(frontText)
        val backTokens  = tokenize(ocrData.fullText)

        val MIN_TOKENS = 6
        val hasEnoughText = frontTokens.size >= MIN_TOKENS && backTokens.size >= MIN_TOKENS

        val jaccard = if (hasEnoughText) {
            val inter = frontTokens.intersect(backTokens).size.toFloat()
            val union = frontTokens.union(backTokens).size.toFloat()
            if (union == 0f) 0f else inter / union
        } else 0f

        log("  dup A â€” frontTokens=${frontTokens.size} backTokens=${backTokens.size} jaccard=${"%.3f".format(jaccard)}")

        if (hasEnoughText) {
            // Jaccard is definitive when text is sufficient
            val isDup = jaccard >= JACCARD_DUPLICATE_THRESHOLD
            return DupCheckResult(
                isDuplicate        = isDup,
                jaccardSimilarity  = jaccard,
                pHashDistance      = -1,
                reason             = if (isDup) "jaccard" else "not_duplicate"
            )
        }

        // â”€â”€ Method B: pHash fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        val pDist = pHashDistance(frontBitmap, backBitmap)
        log("  dup B â€” pHash distance=$pDist (threshold=$PHASH_DUPLICATE_THRESHOLD)")
        val isDupByHash = pDist <= PHASH_DUPLICATE_THRESHOLD

        return DupCheckResult(
            isDuplicate        = isDupByHash,
            jaccardSimilarity  = jaccard,
            pHashDistance      = pDist,
            reason             = if (isDupByHash) "phash" else "not_duplicate"
        )
    }

    // â”€â”€â”€ OCR helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    private suspend fun extractRawOcrText(bitmap: Bitmap): String =
        suspendCoroutine { cont ->
            TextRecognition.getClient(TextRecognizerOptions.DEFAULT_OPTIONS)
                .process(InputImage.fromBitmap(bitmap, 0))
                .addOnSuccessListener { cont.resume(it.text) }
                .addOnFailureListener { cont.resume("") }
        }

    private fun tokenize(text: String): Set<String> =
        text.lowercase()
            .split(Regex("[^a-z0-9]+"))
            .filter { it.length >= 3 }
            .toSet()


    // â”€â”€â”€ pHash â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /**
     * Computes the Hamming distance between the 64-bit pHashes of [a] and [b].
     * Both are cropped to the document region before hashing to remove background.
     * Distance 0 = identical, 64 = completely different.
     */
    private fun pHashDistance(a: Bitmap, b: Bitmap): Int {
        return try {
            val ha = computePHash(cropDocumentRegion(a))
            val hb = computePHash(cropDocumentRegion(b))
            java.lang.Long.bitCount(ha[0] xor hb[0]) +
            java.lang.Long.bitCount(ha[1] xor hb[1])
        } catch (e: Exception) {
            log("pHash error: ${e.message}")
            64 // maximum distance = not similar
        }
    }

    private fun computePHash(bitmap: Bitmap): LongArray {
        val size  = 8
        val small = Bitmap.createScaledBitmap(bitmap, size, size, true)
        val px    = IntArray(size * size)
        small.getPixels(px, 0, size, 0, 0, size, size)
        small.recycle()

        val grays = px.map { p ->
            ((p shr 16 and 0xFF) * 0.299 +
             (p shr  8 and 0xFF) * 0.587 +
             (p        and 0xFF) * 0.114).toInt()
        }
        val avg = grays.average()

        var hi = 0L; var lo = 0L
        for (i in 0 until 64) {
            if (grays[i] >= avg) {
                if (i < 32) hi = hi or (1L shl i)
                else        lo = lo or (1L shl (i - 32))
            }
        }
        return longArrayOf(hi, lo)
    }

    // â”€â”€â”€ Utility â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    private fun log(msg: String) = println("ğŸ“‹ DocValidator | $msg")
}

